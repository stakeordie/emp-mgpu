#!/bin/bash
# Added: 2025-06-03T18:12:16-04:00 - Created mgpu_ollama script to manage ollama in the mgpu environment

set -e

# Added: 2025-06-04T14:01:22-04:00 - Use explicit GPU indices instead of 'all' to fix CPU fallback issue
# Get the number of GPUs from environment or use default
NUM_GPUS=${NUM_GPUS:-1}

# Create a comma-separated list of GPU indices (0,1,2,...)
GPU_INDICES=$(seq -s, 0 $((NUM_GPUS-1)))

# Set environment variables for GPU
export CUDA_VISIBLE_DEVICES=$GPU_INDICES
export CUDA_DEVICE_ORDER=PCI_BUS_ID

# Added: 2025-06-04T14:04:20-04:00 - Modified environment loading to handle errors in /etc/environment
# Load environment variables safely
if [ -f /etc/environment ]; then
  # Source the environment file with error suppression
  set +e  # Temporarily disable exit on error
  source /etc/environment 2>/dev/null || true
  set -e  # Re-enable exit on error
fi

# Default model if not specified in environment
DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL:-"llama3"}
OLLAMA_HOST=${OLLAMA_HOST:-"127.0.0.1"}
OLLAMA_PORT=${OLLAMA_PORT:-"11434"}

# Function to check if ollama is running
check_ollama_running() {
  if pgrep -f "ollama serve" > /dev/null; then
    return 0
  else
    return 1
  fi
}

# Function to start ollama
start_ollama() {
  if check_ollama_running; then
    echo "Ollama is already running"
  else
    echo "Starting ollama server..."
    mkdir -p /workspace/logs
    nohup ollama serve > /workspace/logs/ollama.log 2>&1 &
    
    # Wait for ollama to start
    echo "Waiting for ollama to start..."
    for i in {1..30}; do
      if curl -s "http://${OLLAMA_HOST}:${OLLAMA_PORT}/api/tags" &> /dev/null; then
        echo "Ollama server started successfully"
        return 0
      fi
      sleep 1
    done
    echo "Failed to start ollama server within timeout"
    return 1
  fi
}

# Function to stop ollama
stop_ollama() {
  if check_ollama_running; then
    echo "Stopping ollama server..."
    pkill -f "ollama serve"
    echo "Ollama server stopped"
  else
    echo "Ollama is not running"
  fi
}

# Function to restart ollama
restart_ollama() {
  stop_ollama
  sleep 2
  start_ollama
}

# Function to pull a model
pull_model() {
  local model=$1
  if [ -z "$model" ]; then
    model=$DEFAULT_MODEL
  fi
  
  echo "Pulling model: $model"
  ollama pull $model
}

# Function to list available models
list_models() {
  echo "Available models:"
  ollama list
}

# Function to show ollama status
status() {
  if check_ollama_running; then
    echo "Ollama is running"
    echo "Available models:"
    ollama list
  else
    echo "Ollama is not running"
  fi
}

# Main script logic
case "$1" in
  start)
    start_ollama
    ;;
  stop)
    stop_ollama
    ;;
  restart)
    restart_ollama
    ;;
  pull)
    pull_model "$2"
    ;;
  list)
    list_models
    ;;
  status)
    status
    ;;
  *)
    echo "Usage: $0 {start|stop|restart|pull [model]|list|status}"
    exit 1
    ;;
esac

exit 0
