#!/bin/sh
### BEGIN INIT INFO
# Provides:          ollama
# Required-Start:    $remote_fs $syslog
# Required-Stop:     $remote_fs $syslog
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description: Ollama server
# Description:       Ollama server running in background
### END INIT INFO

# Added: 2025-06-03T18:10:06-04:00 - Created ollama init script to replace langflow

# Change these to match your installation
DIR=/workspace
DAEMON=/usr/local/bin/ollama
DAEMON_NAME=ollama

# Added: 2025-06-04T14:01:22-04:00 - Use explicit GPU indices instead of 'all' to fix CPU fallback issue
# Get the number of GPUs from environment or use default
NUM_GPUS=${NUM_GPUS:-1}

# Create a comma-separated list of GPU indices (0,1,2,...)
GPU_INDICES=$(seq -s, 0 $((NUM_GPUS-1)))

# Set CUDA environment variables
export CUDA_VISIBLE_DEVICES=$GPU_INDICES
export CUDA_DEVICE_ORDER=PCI_BUS_ID

# Added: 2025-06-04T14:04:20-04:00 - Load environment variables safely
if [ -f /etc/environment ]; then
  # Source the environment file with error suppression
  set +e  # Temporarily disable exit on error
  . /etc/environment 2>/dev/null || true
  set -e  # Re-enable exit on error
fi

# This next line determines what user the script runs as
DAEMON_USER=root

# The process ID of the script when it runs is stored here:
PIDFILE=/var/run/$DAEMON_NAME.pid

. /lib/lsb/init-functions

do_start () {
    log_daemon_msg "Starting system $DAEMON_NAME daemon with dynamic GPU selection"
    mkdir -p /workspace/logs
    # Added: 2025-06-04T14:01:22-04:00 - Use explicit GPU indices instead of 'all' to fix CPU fallback issue
    start-stop-daemon --start --background --pidfile $PIDFILE --make-pidfile --user $DAEMON_USER --chuid $DAEMON_USER --startas /bin/bash -- -c "exec env CUDA_VISIBLE_DEVICES=$GPU_INDICES CUDA_DEVICE_ORDER=PCI_BUS_ID $DAEMON serve > /workspace/logs/ollama.log 2>&1"
    sleep 5
    
    # Added: 2025-06-03T18:12:16-04:00 - Pull default model on startup
    # Get default model from environment or use llama3
    DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL:-"llama3"}
    log_daemon_msg "Pulling default model: $DEFAULT_MODEL"
    su - $DAEMON_USER -c "ollama pull $DEFAULT_MODEL >> /workspace/logs/ollama_pull.log 2>&1"
    log_end_msg $?
}

do_stop () {
    log_daemon_msg "Stopping system $DAEMON_NAME daemon"
    start-stop-daemon --stop --pidfile $PIDFILE --retry 10
    log_end_msg $?
}

case "$1" in
    start|stop)
        do_${1}
        ;;

    restart|reload|force-reload)
        do_stop
        do_start
        ;;

    status)
        status_of_proc "$DAEMON_NAME" "$DAEMON" && exit 0 || exit $?
        ;;

    *)
        echo "Usage: /etc/init.d/$DAEMON_NAME {start|stop|restart|status}"
        exit 1
        ;;
esac
exit 0
