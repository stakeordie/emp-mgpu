#!/bin/bash
### BEGIN INIT INFO
# Provides:          a1111
# Required-Start:    $network
# Required-Stop:     $network
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description: Start Automatic1111 Web UI
### END INIT INFO

# 2025-04-12 16:37: Created a1111 service script based on comfyui script

# Paths
ROOT="${ROOT:-/workspace}"
NUM_GPUS="${NUM_GPUS:-0}"  # Default to CPU mode

# Use MOCK_GPU and A1111_ARGS as provided by environment
if [ "${MOCK_GPU:-0}" = "1" ]; then
    export A1111_ARGS="--use-cpu all"
fi

# [2025-04-15T16:25:23-04:00] Function to load environment variables from env.sh
load_environment_variables() {
    local GPU_NUM=$1
    
    if [ -f "/etc/profile.d/env.sh" ]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] [GPU $GPU_NUM] Loading environment variables from /etc/profile.d/env.sh"
        source "/etc/profile.d/env.sh"
    else
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] [GPU $GPU_NUM] WARNING: Environment file /etc/profile.d/env.sh not found"
    fi
}

# Setup logging
setup_logs() {
    local GPU_NUM=$1
    local WORK_DIR="${ROOT}/a1111_gpu${GPU_NUM}"
    
    # Create log directories
    mkdir -p "${WORK_DIR}/logs"
    chmod 755 "${WORK_DIR}/logs"
    
    # Create empty log file if it doesn't exist
    touch "${WORK_DIR}/logs/output.log"
    chmod 644 "${WORK_DIR}/logs/output.log"
}

log() {
    local GPU_NUM=$1
    shift
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    local msg="[A1111 GPU${GPU_NUM}] $*"
    local log_line="[$timestamp] $msg"
    
    # Always write to start.log
    if [ -w "${ROOT}/logs/start.log" ]; then
        echo "$log_line" >> "${ROOT}/logs/start.log"
    else
        echo "WARNING: Cannot write to ${ROOT}/logs/start.log" >&2
    fi
    
    # Write to service-specific logs
    local LOG_DIR="${ROOT}/a1111_gpu${GPU_NUM}/logs"
    
    if [ -d "$LOG_DIR" ]; then
        if [ -w "${LOG_DIR}/output.log" ]; then
            echo "$log_line" >> "${LOG_DIR}/output.log"
        else
            echo "WARNING: Cannot write to ${LOG_DIR}/output.log" >&2
        fi
    fi
    
    # Also output to stderr for service management
    echo "$log_line" >&2
}

start() {
    local GPU_NUM=$1
    local WORK_DIR="${ROOT}/a1111_gpu${GPU_NUM}"
    # [2025-04-15T17:17:42-04:00] Use WORKER_BASE_A1111_PORT + GPU_NUM for port calculation
    local BASE_PORT="${WORKER_BASE_A1111_PORT:-3001}"
    local PORT=$((BASE_PORT + GPU_NUM))
    
    # Log which base port is being used
    if [ -n "${WORKER_BASE_A1111_PORT}" ]; then
        log "$GPU_NUM" "Using WORKER_BASE_A1111_PORT=${WORKER_BASE_A1111_PORT} for port calculation: $PORT"
    else
        log "$GPU_NUM" "WORKER_BASE_A1111_PORT not set, using default base port 3001: $PORT"
    fi
    
    # Setup logs first
    setup_logs "$GPU_NUM"
    
    # [2025-04-15T16:25:23-04:00] Load environment variables before starting service
    load_environment_variables "$GPU_NUM"
    
    # Prevent model downloads if STORAGE_TEST_MODE=true [2025-04-15T09:07:48-04:00]
    if [ "${STORAGE_TEST_MODE:-false}" = "true" ]; then
        log "$GPU_NUM" "STORAGE_TEST_MODE=true: Skipping model download and blocking any model auto-download logic."
        log "$GPU_NUM" "If models are missing, service may not function fully. No download will be attempted."
        # Proceed with service start, but do NOT trigger any model download logic
    fi
    
    # Check if already running
    if [ -f "${WORK_DIR}/a1111.pid" ] && kill -0 "$(cat "${WORK_DIR}/a1111.pid")" 2>/dev/null; then
        if netstat -tuln | grep -q ":$PORT "; then
            log "$GPU_NUM" "Service is already running"
            return 0
        fi
    fi
    
    # Ensure directory exists and has webui.py
    cd "$WORK_DIR" || {
        log "$GPU_NUM" "ERROR: Working directory $WORK_DIR does not exist"
        return 1
    }
    
    # 2025-04-12 18:43: Fixed syntax error, changed } to fi
    if [ ! -f "webui.py" ]; then
        log "$GPU_NUM" "ERROR: webui.py not found in $WORK_DIR"
        return 1
    fi
    
    # Ensure port is free
    if netstat -tuln | grep -q ":$PORT "; then
        log "$GPU_NUM" "ERROR: Port $PORT is already in use"
        return 1
    fi
    
    log "$GPU_NUM" "Starting Automatic1111 service for GPU $GPU_NUM"
    
    # Build command with any additional args
    # 2025-04-14T20:47:00-04:00: Removed duplicate setup logic that's now in mgpu's setup_a1111 function
    # All one-time setup is now done during the initial setup phase, not during service start
    
    # Build command with conda environment
    # 2025-04-14 18:22: Added --skip-sd-models-download flag to prevent model repository downloads
    # 2025-04-14T21:22:00-04:00: Removed --listen flag as it's not needed
    # [2025-04-17T13:18:03-04:00] Changed to use absolute path for better reliability
    # [2025-05-16T16:21:00-04:00] Updated to use conda environment for A1111
    # [2025-05-16T16:42:00-04:00] Removed xformers flag since we're not installing it
    # [2025-05-16T16:43:00-04:00] Added options from reference build.sh: --opt-sdp-no-mem-attention --medvram --no-half-vae
    # [2025-05-16T17:30:00-04:00] Added additional flags to help with PyTorch compatibility issues
    # [2025-05-19T13:38:00-04:00] Add tcmalloc preloading specifically for A1111
    # This isolates tcmalloc to only the A1111 environment where it's needed
    # First check if libtcmalloc exists in the system
    local TCMALLOC_PATH=""
    if [ -f "/usr/lib/x86_64-linux-gnu/libtcmalloc.so" ]; then
        TCMALLOC_PATH="/usr/lib/x86_64-linux-gnu/libtcmalloc.so"
    elif [ -f "/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4" ]; then
        TCMALLOC_PATH="/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4"
    elif [ -f "/usr/lib/libtcmalloc.so" ]; then
        TCMALLOC_PATH="/usr/lib/libtcmalloc.so"
    fi
    
    # Set up the command with or without tcmalloc preloading
    local PRELOAD_CMD=""
    if [ -n "$TCMALLOC_PATH" ]; then
        log "$GPU_NUM" "Using tcmalloc from $TCMALLOC_PATH for A1111"
        PRELOAD_CMD="LD_PRELOAD=$TCMALLOC_PATH"
    else
        log "$GPU_NUM" "Tcmalloc library not found, running without it"
    fi
    
    local CMD="source /opt/conda/bin/activate a1111 && cd /workspace/a1111_gpu${GPU_NUM} && $PRELOAD_CMD python launch.py -f --port $PORT --api --enable-insecure-extension-access --skip-torch-cuda-test --opt-sdp-no-mem-attention --medvram --no-half-vae --precision full --no-half --skip-version-check"
    
    # Add mode-specific args
    log "$GPU_NUM" "A1111: Building command... GPU_NUM=$GPU_NUM MOCK_GPU=${MOCK_GPU:-0}"
    if [ "${MOCK_GPU:-0}" = "1" ]; then
        log "$GPU_NUM" "A1111: Adding --use-cpu all flag (Mock GPU mode)"
        CMD="$CMD --use-cpu all"
    else
        # Check if we have multiple GPUs
        if [ "$NUM_GPUS" -gt 1 ]; then
            # 2025-04-12 19:02: Added --device-id flag for multiple GPU scenarios
            log "$GPU_NUM" "A1111: Adding CUDA_VISIBLE_DEVICES=$GPU_NUM and --device-id $GPU_NUM"
            CMD="CUDA_VISIBLE_DEVICES=$GPU_NUM $CMD --device-id $GPU_NUM"
        else
            log "$GPU_NUM" "A1111: Adding CUDA_VISIBLE_DEVICES=$GPU_NUM"
            CMD="CUDA_VISIBLE_DEVICES=$GPU_NUM $CMD"
        fi
    fi
    
    # Add any additional args from A1111_ARGS
    if [ -n "${A1111_ARGS:-}" ]; then
        if [[ "$CMD" != *"--use-cpu all"* ]]; then
            log "$GPU_NUM" "A1111: Adding additional args: $A1111_ARGS"
            CMD="$CMD $A1111_ARGS"
        else
            log "$GPU_NUM" "A1111: Skipping A1111_ARGS (--use-cpu all already set)"
        fi
    fi
    
    log "$GPU_NUM" "A1111: Running command: $CMD"
    
    # 2025-05-16T17:20:00-04:00: Enhanced logging with timestamps and more verbose output
    log "$GPU_NUM" "Starting A1111 with logs in ${WORK_DIR}/logs/output.log"
    
    # Create a wrapper script to ensure proper logging with timestamps
    cat > "${WORK_DIR}/run_with_logging.sh" << 'EOFSCRIPT'
#!/bin/bash
echo "[$(date '+%Y-%m-%d %H:%M:%S')] A1111 startup script beginning execution"
echo "[$(date '+%Y-%m-%d %H:%M:%S')] ===== A1111 OUTPUT BEGINS BELOW ====="

eval "$1" 2>&1 | while read -r line; do
  echo "[$(date '+%Y-%m-%d %H:%M:%S')] $line"
done
EOFSCRIPT
    
    chmod +x "${WORK_DIR}/run_with_logging.sh"
    
    # Run the command with the logging wrapper
    # 2025-05-16T17:25:00-04:00: Fixed to properly quote the command
    cd "$WORK_DIR" && "${WORK_DIR}/run_with_logging.sh" "$CMD" >> "${WORK_DIR}/logs/output.log" 2>&1 &
    
    echo $! > "${WORK_DIR}/a1111.pid"
    # Save mock state alongside PID
    if [ "${MOCK_GPU:-0}" = "1" ]; then
        echo "1" > "${WORK_DIR}/mock_gpu"
    else
        echo "0" > "${WORK_DIR}/mock_gpu"
    fi
    
    log "$GPU_NUM" "Service started with PID $(cat "${WORK_DIR}/a1111.pid")"
    return 0
}

stop() {
    local GPU_NUM=$1
    local WORK_DIR="${ROOT}/a1111_gpu${GPU_NUM}"
    local PID_FILE="${WORK_DIR}/a1111.pid"
    # [2025-05-22T19:45:00-04:00] Calculate port based on GPU number
    local BASE_PORT="${WORKER_BASE_A1111_PORT:-3001}"
    local PORT=$((BASE_PORT + GPU_NUM))
    
    log "$GPU_NUM" "Stopping A1111 service for GPU $GPU_NUM (port $PORT)..."
    
    # First try to stop using PID file if it exists
    if [ -f "$PID_FILE" ]; then
        local PID
        PID=$(cat "$PID_FILE")
        
        if kill -0 "$PID" 2>/dev/null; then
            log "$GPU_NUM" "Stopping service (PID: $PID)..."
            
            # First try graceful shutdown
            kill -15 "$PID"
            
            # Wait for process to terminate
            local TIMEOUT=30
            local COUNT=0
            while kill -0 "$PID" 2>/dev/null && [ "$COUNT" -lt "$TIMEOUT" ]; do
                sleep 1
                COUNT=$((COUNT + 1))
            done
            
            # If still running, force kill
            if kill -0 "$PID" 2>/dev/null; then
                log "$GPU_NUM" "Process did not terminate gracefully, forcing kill..."
                kill -9 "$PID"
                sleep 1
            fi
            
            # Check if process is still running
            if kill -0 "$PID" 2>/dev/null; then
                log "$GPU_NUM" "ERROR: Failed to kill process $PID"
            else
                log "$GPU_NUM" "Process $PID terminated"
            fi
        else
            log "$GPU_NUM" "Process $PID is not running"
        fi
        
        # Remove PID file regardless of process state
        rm -f "$PID_FILE"
    else
        log "$GPU_NUM" "No PID file found, checking for processes using port $PORT"
    fi
    
    # [2025-05-22T19:45:00-04:00] Check for any processes using the port
    # This is a critical addition to ensure the port is released
    local PORT_PID
    PORT_PID=$(lsof -i:"$PORT" -t 2>/dev/null)
    
    if [ -n "$PORT_PID" ]; then
        log "$GPU_NUM" "Found process(es) using port $PORT: $PORT_PID"
        
        # Kill each process using the port
        for pid in $PORT_PID; do
            log "$GPU_NUM" "Killing process $pid that is using port $PORT"
            kill -15 "$pid" 2>/dev/null
            sleep 1
            
            # Force kill if still running
            if kill -0 "$pid" 2>/dev/null; then
                log "$GPU_NUM" "Process $pid did not terminate gracefully, forcing kill..."
                kill -9 "$pid" 2>/dev/null
                sleep 1
            fi
        done
        
        # Verify port is free
        if lsof -i:"$PORT" -t >/dev/null 2>&1; then
            log "$GPU_NUM" "ERROR: Port $PORT is still in use after kill attempts"
            return 1
        else
            log "$GPU_NUM" "Successfully freed port $PORT"
        fi
    else
        log "$GPU_NUM" "No processes found using port $PORT"
    fi
    
    # [2025-05-22T19:45:00-04:00] Add a small delay to ensure socket is fully closed
    sleep 2
    
    return 0
}

restart() {
    local GPU_NUM=$1
    local WORK_DIR="${ROOT}/a1111_gpu${GPU_NUM}"
    local MOCK_STATE=0
    
    # Save mock state before stopping
    if [ -f "${WORK_DIR}/mock_gpu" ]; then
        MOCK_STATE=$(cat "${WORK_DIR}/mock_gpu")
    fi
    
    # Stop the service
    stop "$GPU_NUM"
    
    # Wait a moment
    sleep 2
    
    # Restore mock state if it was set
    if [ "$MOCK_STATE" = "1" ]; then
        export MOCK_GPU=1
    else
        export MOCK_GPU=0
    fi
    
    # Start the service
    start "$GPU_NUM"
}

status() {
    local GPU_NUM=$1
    local WORK_DIR="${ROOT}/a1111_gpu${GPU_NUM}"
    local PID_FILE="${WORK_DIR}/a1111.pid"
    # 2025-04-14T21:22:00-04:00: Changed port from 3100 to 3001 to match expected configuration
    local PORT=$((3001 + GPU_NUM))
    
    if [ ! -f "$PID_FILE" ]; then
        log "$GPU_NUM" "Service is not running (no PID file)"
        return 3  # Service not running
    fi
    
    local PID
    PID=$(cat "$PID_FILE")
    
    if ! kill -0 "$PID" 2>/dev/null; then
        log "$GPU_NUM" "Service is not running (PID $PID not found)"
        return 1  # Program dead, but PID file exists
    fi
    
    # Check if port is actually listening
    if ! netstat -tuln | grep -q ":$PORT "; then
        log "$GPU_NUM" "Service process is running (PID $PID), but port $PORT is not listening"
        return 2  # Service running but not responding
    fi
    
    # Get uptime
    local START_TIME
    if [ -f "/proc/$PID/stat" ]; then
        START_TIME=$(stat -c %Y "/proc/$PID/stat")
        local CURRENT_TIME
        CURRENT_TIME=$(date +%s)
        local UPTIME=$((CURRENT_TIME - START_TIME))
        local UPTIME_FORMATTED
        UPTIME_FORMATTED=$(printf '%dd %dh %dm %ds' $((UPTIME/86400)) $((UPTIME%86400/3600)) $((UPTIME%3600/60)) $((UPTIME%60)))
        log "$GPU_NUM" "Service is running (PID $PID, uptime: $UPTIME_FORMATTED)"
    else
        log "$GPU_NUM" "Service is running (PID $PID)"
    fi
    
    return 0  # Service running
}

case "$1" in
    start|stop|status|restart)
        # Set mock mode only if test_gpus is provided and not 0
        if [ -n "$3" ] && [ "$3" != "0" ]; then
            export MOCK_GPU=1
        fi
        
        "$1" "$2"
        exit $?
        ;;
    *)
        echo "Usage: $0 {start|stop|restart|status} <gpu_id> [test_gpus]"
        exit 1
        ;;
esac
